{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc440228-6038-48db-ba8b-a600049f3f2f",
   "metadata": {},
   "source": [
    "# Managing Machine Learning Models with MLflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4fcc5e-32f3-42d2-b20f-60e4d8b7f8e1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- Weston Bassler ML Engineer at Emburse\n",
    "- DevOps / SRE \n",
    "- Distributed Systems Background (Hadoop, Apache Mesos, Kubernetes)\n",
    "- Love Tech and Automation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60181d65-d28f-410f-9b4d-535701882efd",
   "metadata": {},
   "source": [
    "## What am I going to show you today?\n",
    "- What is MLflow?\n",
    "- Experiment Tracking\n",
    "- Model Evaluation\n",
    "- Model Registry\n",
    "- Model Deployment\n",
    "- Automate Training\n",
    "\n",
    "** Please use the Notebook to follow along **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099bb34c-2444-41fa-81ed-0049263a8f26",
   "metadata": {},
   "source": [
    "# What is MLflow?\n",
    "- A powerful Python Library that assists many steps of the the Machine Learning (ML) lifecycle\n",
    "- It contains of Tracking, Models, Model Registry and Model Serving\n",
    "- Has integrations with many tools and platforms such as: PyTorch, Tensorflow, scikit-lear, HuggingFace, LangChain, OpenAI and many many more...\n",
    "- It is Open Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d794c58-de1b-4d44-8cad-2fc560fd8c66",
   "metadata": {},
   "source": [
    "# Why should you care?\n",
    "\n",
    "*The Application Development Lifecycle is hard. Application Development that includes Machine Learning (ML Lifecycle) is even harder!*\n",
    "\n",
    "MLflow simplies the ML Lifecycle by providing solutions for the following:\n",
    "\n",
    "- Experimentation Management (**MLflow Tracking**): MLflow provides a systematic way to track experiments, including parameters, metrics, and code versions. This helps you organize and compare different experiments easily, leading to more efficient exploration of hyperparameters and model architectures.\n",
    "\n",
    "- Reproducibility and Collaboration (**MLflow Tracking & MLflow Projects & Model Registry**): MLflow captures the environment and dependencies for each experiment, ensuring reproducibility across different environments. This is crucial for collaboration within teams and sharing results with stakeholders, as it ensures that experiments can be replicated reliably.\n",
    "\n",
    "- Model Versioning and Management (**Model Registry**): MLflow allows you to version models, making it easier to track changes over time and revert to previous versions if needed. This enhances model governance and facilitates auditing and compliance requirements.\n",
    "\n",
    "- Deployment Simplification (**Model Registry**): MLflow streamlines the process of deploying models into production by providing tools for packaging models in a standard format and integrating with deployment platforms. This reduces the friction between model development and deployment, enabling faster time-to-market for machine learning solutions.\n",
    "\n",
    "- Integration with Existing Tools and Frameworks (**MLflow Models/Flavors**): MLflow seamlessly integrates with popular machine learning libraries and frameworks, including TensorFlow, PyTorch, scikit-learn, and XGBoost. This means you can continue using your preferred tools while benefiting from MLflow's capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fd9b2-d1f4-4304-9f25-f382c8ab6441",
   "metadata": {},
   "source": [
    "# Using MLflow Python API\n",
    "\n",
    "#### MLflow Module\n",
    "- The `mlflow` module is an for managing MLflow Runs.\n",
    "- What is a Run? Collection of parameters, metrics, artifacts, etc.. related to training an ML Model\n",
    "- \"Active\"\n",
    "```py\n",
    "import mlflow\n",
    "\n",
    "# to start a run\n",
    "mlflow.start_run()\n",
    "\n",
    "# to end a run\n",
    "mlflow.end_run()\n",
    "\n",
    "```\n",
    "\n",
    "#### MLflow Client\n",
    "- Used to interface with Experiments, Runs, Model Versions and Registered Models.\n",
    "```py\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897a8b0-9611-438f-9005-2397341358a6",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33335368-1dde-4400-9c3f-9b6be8fd9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow==2.8.1 pandas==1.5.1 xgboost==1.6.2 argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e663c8a-1bcf-4d1d-be3a-aaa6d4bec58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF YOU ARE USING GOOGLE COLAB UNCOMMENT AND RUN\n",
    "# !git clone https://github.com/geekbass/MLflow-Workshop.git\n",
    "# !rm MLflow-Workshop/*ipynb\n",
    "# !mv MLflow-Workshop/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef65e5d-b053-4a40-8c50-03fa6224bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF YOU ARE USING GOOGLE COLAB UNCOMMENT AND RUN\n",
    "# import shutil\n",
    "\n",
    "# shutil.rmtree('MLflow-Workshop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9c4d9-0448-4ec4-9360-16d390b8e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "RESTART YOUR KERNEL\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a619d821-8d98-4a09-98fa-084fa25390d8",
   "metadata": {},
   "source": [
    "# Project Background\n",
    "We are an investment firm that finanically backs startup tech companies. The company believes that they could benefit from an ML model that could estimate the potential profit based on historical data from previous investments.\n",
    "\n",
    "We have a dataset that we have collected that estimates the potenital profit of a startup based on the spend of R&D, Administration, and Maketing as well as which U.S. state the startup will reside. \n",
    "\n",
    "We have decided that the model should be a Regression Type model and we are going to use XGBoost Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ff8a1-58ea-4053-87d8-e7d5ae374a33",
   "metadata": {},
   "source": [
    "# Create your Project in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d9e29-0948-421c-851d-0a45b005c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Your Initial Project in MLflow\n",
    "import mlflow \n",
    "\n",
    "# Set the a tracking URI to a local sqlite file\n",
    "mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")\n",
    "\n",
    "# In MLflow create a new Experiment \n",
    "experiment_id = mlflow.create_experiment(\"PotentialStartups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3771c-d182-4f6a-86ec-ce075ec54a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Experiment Name and Creation Date\n",
    "experiment = mlflow.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Creation timestamp: {}\".format(experiment.creation_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90d74a-deb6-4920-937c-eaa7cc41d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an MLFlow UI for a Visual\n",
    "!mlflow server --backend-store-uri=\"sqlite:///mydb.sqlite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb983f8f-6331-4f49-b7b9-8d2fd30d3a2e",
   "metadata": {},
   "source": [
    "# Track your First Model | MLflow Tracking \n",
    "Here we are going to create a project so that we can store and log information about our training runs to MLflow. MLflow Tracking provides a central location for visualizations and storing information about models such as training parameters, metrics, and even store files such as models, code, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294b0a7-5834-4009-917f-44ea821443df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin with loading the Dataset into Training Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Dataset\n",
    "df = pd.read_csv('startups_profit.csv', index_col=False)\n",
    "df['State']=df['State'].map({'New York':0,'Florida':1, 'California': 2}).astype(int)\n",
    "\n",
    "# Training Data\n",
    "X = df[[\"R&D Spend\", \"Administration\", \"Marketing Spend\",\"State\"]]\n",
    "y = df[[\"Profit\"]]\n",
    "X, y = df.iloc[:, :-1], df.iloc[:, -1] \n",
    "\n",
    "# Setting up train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y), train_size=0.7,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc5284-2775-4fec-ad9e-2c72e2cd7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d21ed4-5bae-4363-9b12-f84733df7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log model to our Project\n",
    "import mlflow\n",
    "\n",
    "# Set the connection to the tracking URI\n",
    "mlflow.____\n",
    "# Set the experiment\n",
    "mlflow.set_experiment(\"PotentialStartups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8804a5d-a6bf-4dcb-9a62-f88d9dad5a4a",
   "metadata": {},
   "source": [
    "### Lets Talk about Auto Logging in MLflow\n",
    "What is `autolog`? \n",
    "\n",
    "MLflow has integrations with some ML libraries that will automatically log metrics, parameters, and models by simply calling `autolog()` method.\n",
    "\n",
    "The following libraries support autologging:\n",
    "- Fastai\n",
    "- Gluon\n",
    "- Keras\n",
    "- LightGBM\n",
    "- PyTorch\n",
    "- Scikit-learn\n",
    "- Spark\n",
    "- Statsmodels\n",
    "- XGBoost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4170f-df24-4f6a-819e-bab03b52219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start an MLflow Run\n",
    "mlflow.____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1d25d-cd16-4cfb-8611-903ecf834d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Autolog for XGBoost\n",
    "import mlflow.xgboost\n",
    "\n",
    "mlflow.xgboost.____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c193d450-7c99-4f83-a459-9a426c478516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our First Model\n",
    "import xgboost \n",
    "\n",
    "xgbr = xgboost.XGBRegressor() \n",
    "xgbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652c13f-ec68-4556-9471-76f91f5871c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate our Model using MLflow. This is Log the metrics for us to MLflow.\n",
    "eval_data = X_test\n",
    "eval_data[\"Profits\"] = y_test\n",
    "\n",
    "# This will load our Model\n",
    "model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "\n",
    "# This will run the evaluate Method against our model and our evaluation Data for the Regressor Type.\n",
    "# Here we are also only selecting the \"default\" evaluators\n",
    "result = mlflow.evaluate(\n",
    "    model_uri,\n",
    "    eval_data,\n",
    "    targets=\"Profits\",\n",
    "    model_type=\"regressor\",\n",
    "    evaluators=\"default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36b3aa-326f-46d8-aaf3-86c62ba6b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End our Run\n",
    "mlflow.____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9fb0d-4ce9-449d-b1f2-62ea7d6be951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this Cell a few times just to populate some data\n",
    "import mlflow.xgboost\n",
    "import xgboost\n",
    "\n",
    "# Start another MLflow Run\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.xgboost.autolog()\n",
    "\n",
    "    xgbr = xgboost.XGBRegressor() \n",
    "    xgbr.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate our Model using MLflow\n",
    "    eval_data = X_test\n",
    "    eval_data[\"Profits\"] = y_test\n",
    "    \n",
    "    # This will load our Model\n",
    "    model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "    \n",
    "    # Set the evaluation function\n",
    "    result = mlflow.____(\n",
    "        model_uri,\n",
    "        eval_data,\n",
    "        targets=\"Profits\",\n",
    "        model_type=\"regressor\",\n",
    "        evaluators=\"default\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c86a77-0b5e-4dd6-8290-4ae8c68202b4",
   "metadata": {},
   "source": [
    "# Evaluate our Trained Models based on Metrics\n",
    "Just like we have in the UI, you can also sift through metrics for an Experiment. We can use Pandas for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5653161-2b8f-4d88-8143-f0485f362c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Set Tracking URL \n",
    "mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")\n",
    "\n",
    "# Get the Experiment ID\n",
    "experiment_id = mlflow.get_experiment_by_name(\"PotentialStartups\").experiment_id\n",
    "\n",
    "# Search runs and output to Pandas DF\n",
    "evals_df = mlflow.search_runs([experiment_id])\n",
    "evals_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e8714-97b7-4c32-bf30-23745277479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02fd45-f93a-436b-b1e1-5ac29df8810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort it by r2_score\n",
    "evals_df = mlflow.search_runs([experiment_id], order_by=[\"metrics.r2_score DESC\"])\n",
    "evals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bec072-5078-4643-ba5e-7cdb9ea5b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print ONLY the r2_score and the run_id\n",
    "evals_df[[____, ____]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a35d2-e231-48e2-b91a-73d3c16bb207",
   "metadata": {},
   "source": [
    "#### The above evaluation can be done on ANY metric you would like. This will help us decide which models we would like to Regster to the Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2805a3e8-691d-4d35-a705-9cd4d180a369",
   "metadata": {},
   "source": [
    "# Register A Model | MLflow Registry\n",
    "The Model Registry is used as a way to store models in a way that allows for us to share models easily to others while also following the development lifecycle (Staging, Production, etc...). It also provides a way to version, alias, tag and annotate models as desired. \n",
    "\n",
    "We have now trained a few models and have evaluated the results. We have a model ready for initial testing and need to establish a method for team members and other company personnel to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14bf7b-4691-4763-afa1-c5672ca2c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a New Model in The Model Registry using the MLflow Client\n",
    "import mlflow\n",
    "\n",
    "# Set out tracking URI\n",
    "mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")\n",
    "\n",
    "# Create a client connection\n",
    "client = mlflow._____\n",
    "\n",
    "# Create a new Model in the Registry called StartupModels\n",
    "client.create_registered_model(\"StartupModels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be494ee-8319-488c-9e71-5c8db460c197",
   "metadata": {},
   "source": [
    "#### Now that we have a location to store our models lets register (add) a model to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3945f71-eeca-42cd-a86b-6fac93e44d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# SET THESE 2 lines\n",
    "mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")\n",
    "mlflow.set_experiment(\"PotentialStartups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994dd45f-b15f-400e-b5f8-77805fb79778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To begin using the Model Registry, Pick our favorite model from above and register it using the run-id\n",
    "run_id = ____\n",
    "\n",
    "# Register the model\n",
    "mlflow.register_model(f\"runs:/{run_id}/model\", \"StartupModels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23459c79-8995-4eaf-8068-33e594f368eb",
   "metadata": {},
   "source": [
    "#### Notice here, a new version of the model has been created. We could add another model here and it would continue to increment the version. This is very good practice. \n",
    "\n",
    "#### Also note here, MLflow increments versions but we can also add our own tags and aliases to models to better help identify them. This is out of scope for this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f632a-6c1f-4a51-930e-0a407cfd6b80",
   "metadata": {},
   "source": [
    "# Deploying a Model | MLflow Registry\n",
    "Now that we have a model registered to the Model Registry, we can now use MLflow to Deploy the model. Anyone that has access to MLflow can do this. For now we are going to deploy the model locally using the version of the model when we first registered it.\n",
    "\n",
    "We will load it via the \"model_uri\" - `models:/model_name/model_version`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3c393-b9e1-4a8a-a6e9-b97b63a2f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set the tracking URI\n",
    "mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517da38f-dbce-47b2-82f0-9eaa3e7c5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Notice here we actually use mlflow XGBoost \"flavor\" to load the model. Check the MLflow Docs for more information on Flavors!\n",
    "model = mlflow.xgboost.load_model(model_uri=\"models:/StartupModels/1\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e5f69-735d-48c6-b4f4-e1dd886ffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a quick Prediction on profit using some fake data\n",
    "\n",
    "# R&D Spend, Administration, Marketing Spend, State\n",
    "predict_list = [345349.2, 133337.8, 472345.10, 1]\n",
    "# Predict\n",
    "prediction = model.predict([predict_list])\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac3a11a-5526-4bae-aede-3bbfbb7b8ec6",
   "metadata": {},
   "source": [
    "### Serving via CLI\n",
    "Below is an example shell script using the MLflow CLI for serving the same model. It will serve the model via port 5000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb0785-4fe2-4b61-b30e-5abd2332e4be",
   "metadata": {},
   "source": [
    "```sh\n",
    "#!/usr/bin/env sh\n",
    "\n",
    "# Deploying a Model using the mlflow cli\n",
    "export MLFLOW_TRACKING_URI=\"sqlite:///mydb.sqlite\"\n",
    "\n",
    "# Serve the model from the \n",
    "mlflow models serve -m \"models:/StartupModels/1\" --no-conda\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c436f-4a0a-4df1-b057-6c1c116f21a7",
   "metadata": {},
   "source": [
    "# Automating Training | MLflow Projects\n",
    "As we iterate new model versions, add new data and learn from our experimentations it becomes more of a need to implement automation into our development pipeline. This is where MLflow Projects come in. MLflow Projects is a format used to package all of our code into a reproducible way. It also provides a way for us to run the automation via CLI or from the `projects()` function. \n",
    "\n",
    "We specify our Project in a file called `MLproject` which is a yaml file that specifies key pieces such as name, python environment and entry points which are ways that we can pass templated parameters and commands to scripts.\n",
    "\n",
    "Below is an example `MLproject` file that we will be using:\n",
    "\n",
    "```\n",
    "name: Potential Profit \n",
    "\n",
    "python_env: python_env.yaml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      n_estimators: {type: int, default: 10}\n",
    "      max_depth: {type: int, default: 5}\n",
    "    command: \"python train.py \\\n",
    "        --n_estimators {n_estimators} \\\n",
    "        --max_depth {max_depth}\"\n",
    "```\n",
    "\n",
    "The above file will allow for us to pass the parameters of `n_estimators` and `max_depth` to our command which is a python script that accepts two arguments (n_estimators` and `max_depth`). This will help us to automate a training run where we can then pass different parameters using the same code. For this we will use Argparse library.\n",
    "\n",
    "**We can automate an entire training run very very easily! Everything we have done so far we will automate with an MLflow Project!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7d42e-87ea-4cfd-88c2-f59b26602190",
   "metadata": {},
   "source": [
    "Our `train.py` file looks like this:\n",
    "\n",
    "```py\n",
    "import sys\n",
    "import argparse\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set MLflow tracking server and the Experiment Name\n",
    "mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")\n",
    "\n",
    "# Parse out our parameter Arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--n_estimators')\n",
    "parser.add_argument('--max_depth')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Set the values of our Arguments\n",
    "n_estimators = int(args.n_estimators)\n",
    "max_depth = int(args.max_depth)\n",
    "\n",
    "# Set up the Training Data\n",
    "# Load the Dataset\n",
    "df = pd.read_csv('startups_profit.csv', index_col=False)\n",
    "df['State']=df['State'].map({'New York':0,'Florida':1, 'California': 2}).astype(int)\n",
    "\n",
    "# Training Data\n",
    "X = df[[\"R&D Spend\", \"Administration\", \"Marketing Spend\",\"State\"]]\n",
    "y = df[[\"Profit\"]]\n",
    "X, y = df.iloc[:, :-1], df.iloc[:, -1] \n",
    "\n",
    "# Setting up train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y), train_size=0.7,random_state=0)\n",
    "\n",
    "# Start a training Run and autolog it.\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.xgboost.autolog()\n",
    "    xgbr = xgboost.XGBRegressor(n_estimators=n_estimators, max_depth=max_depth) \n",
    "    xgbr.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate our Model using MLflow\n",
    "    eval_data = X_test\n",
    "    eval_data[\"Profits\"] = y_test\n",
    "    \n",
    "    # Load the model\n",
    "    model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "    \n",
    "    # Evaluate the model and autolog it\n",
    "    result = mlflow.evaluate(\n",
    "        model_uri,\n",
    "        eval_data,\n",
    "        targets=\"Profits\",\n",
    "        model_type=\"regressor\",\n",
    "        evaluators=\"default\"\n",
    "    )\n",
    "\n",
    "```\n",
    "\n",
    "You can see all the steps that we have done before to train our model except we are now adding parameters to our model which is going to be passed via MLflow Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d5ed7-3353-4fc9-83ff-72ed0ac6910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets run a Project using the projects function\n",
    "import mlflow\n",
    "\n",
    "# Set our tracking uri\n",
    "mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")\n",
    "\n",
    "# Run the projects with our specified parameters\n",
    "mlflow.projects.run(\n",
    "    # Specifies where the MLproject file lives\n",
    "    './',\n",
    "    # Running this on the main entry point\n",
    "    entry_point='main',\n",
    "    # Here is our Experiment Name.\n",
    "    experiment_name='PotentialStartups',\n",
    "    # Using the local environment\n",
    "    env_manager='local',\n",
    "    # Set our Desired parameters for our model\n",
    "    parameters={\n",
    "        'n_estimators': 20, \n",
    "        'max_depth': 5\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95140cb-fc08-4b80-8799-8368d96bfab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just check to make sure it worked\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Set Tracking URL \n",
    "mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")\n",
    "\n",
    "# Get the Experiment ID\n",
    "experiment_id = mlflow.get_experiment_by_name(\"PotentialStartups\").experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d8d9b-9739-42e1-bada-512652ba224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search runs and output to Pandas DF. You can get the run_id from the output from the Project run.\n",
    "evals_df = mlflow.____([experiment_id])\n",
    "evals_df['run_id']==____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21da6d4-55c2-4962-97fd-da37f84c6ffe",
   "metadata": {},
   "source": [
    "## Taking Automation Further with Projects\n",
    "- Use tools like Dask or Ray to train multiple Models at a time with different Parameters\n",
    "- Dask Hyperparameter Search is a great option\n",
    "- Train multiple models at the same time in parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571c1f6-9157-4abf-a904-7ab329353a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a094bb0-4e97-48b1-b2d6-0ea40b2b828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating a list of parameters to be passed to our train_model function below.\n",
    "import random\n",
    "\n",
    "parameters = [\n",
    "    {'n_estimators': 10, 'max_depth': 2},\n",
    "    {'n_estimators': 50, 'max_depth': 3},\n",
    "    {'n_estimators': 100, 'max_depth': 4},\n",
    "    {'n_estimators': 20, 'max_depth': 5},\n",
    "    {'n_estimators': 150, 'max_depth': 6},\n",
    "    {'n_estimators': 250, 'max_depth': 7},\n",
    "    {'n_estimators': random.randint(0, 250), 'max_depth': 8},\n",
    "    {'n_estimators': random.randint(0, 250), 'max_depth': 9},\n",
    "    {'n_estimators': random.randint(0, 250), 'max_depth': 10},\n",
    "    {'n_estimators': random.randint(0, 250), 'max_depth': 9},\n",
    "    {'n_estimators': random.randint(0, 250), 'max_depth': 8},\n",
    "    {'n_estimators': random.randint(0, 250), 'max_depth': 7},\n",
    "    {'n_estimators': random.randint(0, 250), 'max_depth': 6},\n",
    "    {'n_estimators': random.randint(0, 250), 'max_depth': 5},\n",
    "    {'n_estimators': random.randint(0, 250), 'max_depth': 10}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1291d6-9285-4840-9717-bfc976e5db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699c8ac-7b8e-4065-a0e0-0367c60c96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same Projects functions as above but we take the parameters from a dictionary in dask delayed decorator\n",
    "import dask\n",
    "import mlflow\n",
    "\n",
    "@dask.delayed\n",
    "def train_model(parameters):\n",
    "    # Set our tracking uri\n",
    "    mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")\n",
    "\n",
    "    # Run the projects with our specified parameters\n",
    "    mlflow.projects.run(\n",
    "        # Specifies where the MLproject file lives\n",
    "        './',\n",
    "        # Running this on the main entry point\n",
    "        entry_point='main',\n",
    "        # Here is our Experiment Name.\n",
    "        experiment_name='PotentialStartups',\n",
    "        # Using the local environment\n",
    "        env_manager='local',\n",
    "        # Set our Desired parameters for our model\n",
    "        parameters={\n",
    "            'n_estimators': parameters['n_estimators'], \n",
    "            'max_depth': parameters['max_depth']\n",
    "        })\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f205a-c4b7-4e48-aab6-e59a194917d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Append the results for each dictionary of parameters\n",
    "for param in parameters:\n",
    "    results.append(train_model(param))\n",
    "\n",
    "# Compute it in parallel\n",
    "dask.compute(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18255fcf-ad6d-45c4-a8e3-505d6a6402bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all the new ones\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Set Tracking URL \n",
    "mlflow.set_tracking_uri(\"sqlite:///mydb.sqlite\")\n",
    "\n",
    "# Get the Experiment ID\n",
    "experiment_id = mlflow.get_experiment_by_name(\"PotentialStartups\").experiment_id\n",
    "\n",
    "# Sort it by r2_score and show which parameters gave us the best result\n",
    "evals_df = mlflow.search_runs([experiment_id], order_by=[\"metrics.r2_score DESC\"])\n",
    "evals_df[[\"metrics.r2_score\", \"run_id\", \"params.max_depth\", \"params.n_estimators\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604f50d-a3bd-434f-8fae-c0136733a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Register the \"BEST\" model\n",
    "run_id = \"a552865619f043b4a5a88bfda2738a24\"\n",
    "\n",
    "# Register the model\n",
    "mlflow.register_model(f\"runs:/{run_id}/model\", \"StartupModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd55ec2-effb-422e-9084-42d3f30a15a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and run prediction on BEST model\n",
    "import mlflow\n",
    "\n",
    "# Load Second version\n",
    "model = mlflow.xgboost.load_model(model_uri=\"models:/StartupModels/2\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9f794-dc32-4279-bb31-2f77ef9b71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print params\n",
    "model.max_depth, model.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfddcf5-60c0-4e81-b564-018c219c9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R&D Spend, Administration, Marketing Spend, State\n",
    "predict_list = [13345349.2, 200000.8, 100000.0, 0]\n",
    "# Predict\n",
    "prediction = model.predict([predict_list])\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8779150-5013-4e8a-8223-f2dacbd97a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
